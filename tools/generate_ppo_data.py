# -*- coding: utf-8 -*-
"""
PowerNexus - PPO è®­ç»ƒæ•°æ®ç”Ÿæˆè„šæœ¬

ä¸“é—¨ä¸º PPO è®­ç»ƒç”Ÿæˆç”µç½‘çŠ¶æ€æ•°æ®çš„ä¾¿æ·è„šæœ¬ã€‚
åŸºäº simulate_grid_state.pyï¼Œæä¾›æ›´ç®€å•çš„æ¥å£ã€‚

ä½¿ç”¨æ–¹æ³•:
    # ç”Ÿæˆé»˜è®¤è®­ç»ƒæ•°æ® (1000ä¸ªæ ·æœ¬ï¼Œæ··åˆåœºæ™¯)
    python tools/generate_ppo_data.py
    
    # ç”Ÿæˆæ›´å¤šæ ·æœ¬
    python tools/generate_ppo_data.py --samples 5000
    
    # ç”Ÿæˆç‰¹å®šåœºæ™¯æ•°æ®
    python tools/generate_ppo_data.py --scenario overload --samples 500
    
    # ç”Ÿæˆå®Œæ•´è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†
    python tools/generate_ppo_data.py --full-dataset

ä½œè€…: PowerNexus Team
æ—¥æœŸ: 2025-12-20
"""

import argparse
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from tools.simulate_grid_state import GridStateGenerator, GridConfig, GenerationConfig


def generate_training_data(
    n_samples: int = 1000,
    scenario: str = "mixed",
    output_dir: str = "data",
    seed: int = None,
):
    """
    ç”Ÿæˆ PPO è®­ç»ƒæ•°æ®
    
    Args:
        n_samples: æ ·æœ¬æ•°é‡
        scenario: åœºæ™¯ç±»å‹ (normal, high_load, overload, mixed)
        output_dir: è¾“å‡ºç›®å½•
        seed: éšæœºç§å­
    """
    print("=" * 60)
    print("PowerNexus - PPO è®­ç»ƒæ•°æ®ç”Ÿæˆå™¨")
    print("=" * 60)
    print()
    
    # åˆ›å»ºç”Ÿæˆå™¨
    generator = GridStateGenerator(seed=seed)
    
    # ç”Ÿæˆæ•°æ®
    print(f"ç”Ÿæˆ {n_samples} ä¸ªç”µç½‘çŠ¶æ€ (åœºæ™¯: {scenario})...")
    
    if scenario == "weighted":
        # æŒ‰æƒé‡ç”Ÿæˆä¸åŒåœºæ™¯ï¼Œæ›´é€‚åˆè®­ç»ƒ
        scenario_weights = {
            "normal": 0.4,      # 40% æ­£å¸¸è¿è¡Œ
            "high_load": 0.35,  # 35% é«˜è´Ÿè·
            "overload": 0.20,   # 20% è¿‡è½½
            "mixed": 0.05,      # 5% æ··åˆ
        }
        states = generator.generate_mixed_scenarios(n_samples, scenario_weights)
    else:
        states = generator.generate_batch(n_samples, scenario)
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    generator.print_statistics(states)
    
    # ä¿å­˜æ•°æ®
    output_path = Path(output_dir) / "grid_states.npz"
    generator.save_to_npz(states, output_path)
    
    print(f"\nâœ… æ•°æ®å·²ä¿å­˜åˆ°: {output_path}")
    print(f"   æ ·æœ¬æ•°é‡: {len(states)}")
    print(f"   è§‚æµ‹ç»´åº¦: {states[0].to_observation().shape[0]}")
    
    return output_path


def generate_full_dataset(
    train_samples: int = 5000,
    val_samples: int = 1000,
    test_samples: int = 1000,
    output_dir: str = "data/ppo_dataset",
    seed: int = 42,
):
    """
    ç”Ÿæˆå®Œæ•´çš„è®­ç»ƒ/éªŒè¯/æµ‹è¯•æ•°æ®é›†
    
    Args:
        train_samples: è®­ç»ƒé›†æ ·æœ¬æ•°
        val_samples: éªŒè¯é›†æ ·æœ¬æ•°
        test_samples: æµ‹è¯•é›†æ ·æœ¬æ•°
        output_dir: è¾“å‡ºç›®å½•
        seed: éšæœºç§å­
    """
    print("=" * 60)
    print("PowerNexus - å®Œæ•´ PPO æ•°æ®é›†ç”Ÿæˆå™¨")
    print("=" * 60)
    print()
    
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    # ç”Ÿæˆå™¨é…ç½®
    generator = GridStateGenerator(seed=seed)
    
    # åœºæ™¯æƒé‡é…ç½®
    train_weights = {
        "normal": 0.35,
        "high_load": 0.35,
        "overload": 0.25,
        "mixed": 0.05,
    }
    
    val_test_weights = {
        "normal": 0.4,
        "high_load": 0.3,
        "overload": 0.2,
        "mixed": 0.1,
    }
    
    # ç”Ÿæˆè®­ç»ƒé›†
    print(f"\nğŸ“Š ç”Ÿæˆè®­ç»ƒé›† ({train_samples} æ ·æœ¬)...")
    train_states = generator.generate_mixed_scenarios(train_samples, train_weights)
    generator.save_to_npz(train_states, output_path / "train.npz")
    print(f"   âœ… ä¿å­˜åˆ°: {output_path / 'train.npz'}")
    
    # ç”ŸæˆéªŒè¯é›†
    print(f"\nğŸ“Š ç”ŸæˆéªŒè¯é›† ({val_samples} æ ·æœ¬)...")
    val_states = generator.generate_mixed_scenarios(val_samples, val_test_weights)
    generator.save_to_npz(val_states, output_path / "val.npz")
    print(f"   âœ… ä¿å­˜åˆ°: {output_path / 'val.npz'}")
    
    # ç”Ÿæˆæµ‹è¯•é›†
    print(f"\nğŸ“Š ç”Ÿæˆæµ‹è¯•é›† ({test_samples} æ ·æœ¬)...")
    test_states = generator.generate_mixed_scenarios(test_samples, val_test_weights)
    generator.save_to_npz(test_states, output_path / "test.npz")
    print(f"   âœ… ä¿å­˜åˆ°: {output_path / 'test.npz'}")
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    print("æ•°æ®é›†ç”Ÿæˆå®Œæˆ!")
    print("=" * 60)
    print(f"""
æ•°æ®é›†è·¯å¾„: {output_path}
â”œâ”€â”€ train.npz  ({train_samples} æ ·æœ¬)
â”œâ”€â”€ val.npz    ({val_samples} æ ·æœ¬)  
â””â”€â”€ test.npz   ({test_samples} æ ·æœ¬)

æ€»è®¡: {train_samples + val_samples + test_samples} æ ·æœ¬

ä½¿ç”¨æ–¹æ³•:
  1. PPO è®­ç»ƒ:
     python tools/train_ppo.py --timesteps 100000
  
  2. åŠ è½½æ•°æ®è¿›è¡Œè‡ªå®šä¹‰è®­ç»ƒ:
     import numpy as np
     data = np.load('data/ppo_dataset/train.npz')
     observations = np.concatenate([
         data['rho'], data['gen_p'], data['gen_v'],
         data['load_p'], data['load_q'], data['topo_vect']
     ], axis=1)
""")
    
    return output_path


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="PowerNexus PPO è®­ç»ƒæ•°æ®ç”Ÿæˆå™¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # ç”Ÿæˆé»˜è®¤è®­ç»ƒæ•°æ® (1000 æ ·æœ¬)
  python tools/generate_ppo_data.py

  # ç”Ÿæˆ 5000 æ ·æœ¬ï¼Œè¿‡è½½åœºæ™¯
  python tools/generate_ppo_data.py --samples 5000 --scenario overload

  # ç”Ÿæˆå®Œæ•´æ•°æ®é›† (è®­ç»ƒ/éªŒè¯/æµ‹è¯•)
  python tools/generate_ppo_data.py --full-dataset

  # ç”Ÿæˆå¤§è§„æ¨¡è®­ç»ƒé›†
  python tools/generate_ppo_data.py --full-dataset --train-samples 10000
        """
    )
    
    parser.add_argument(
        "--samples", "-n",
        type=int,
        default=1000,
        help="æ ·æœ¬æ•°é‡ (é»˜è®¤: 1000)"
    )
    
    parser.add_argument(
        "--scenario", "-s",
        type=str,
        default="weighted",
        choices=["normal", "high_load", "overload", "mixed", "weighted"],
        help="åœºæ™¯ç±»å‹ (é»˜è®¤: weightedï¼ŒæŒ‰æ¯”ä¾‹æ··åˆå„åœºæ™¯)"
    )
    
    parser.add_argument(
        "--output", "-o",
        type=str,
        default="data",
        help="è¾“å‡ºç›®å½• (é»˜è®¤: data)"
    )
    
    parser.add_argument(
        "--seed",
        type=int,
        default=42,
        help="éšæœºç§å­ (é»˜è®¤: 42)"
    )
    
    parser.add_argument(
        "--full-dataset",
        action="store_true",
        help="ç”Ÿæˆå®Œæ•´çš„è®­ç»ƒ/éªŒè¯/æµ‹è¯•æ•°æ®é›†"
    )
    
    parser.add_argument(
        "--train-samples",
        type=int,
        default=5000,
        help="è®­ç»ƒé›†æ ·æœ¬æ•° (ä»… --full-dataset æ¨¡å¼ï¼Œé»˜è®¤: 5000)"
    )
    
    parser.add_argument(
        "--val-samples",
        type=int,
        default=1000,
        help="éªŒè¯é›†æ ·æœ¬æ•° (ä»… --full-dataset æ¨¡å¼ï¼Œé»˜è®¤: 1000)"
    )
    
    parser.add_argument(
        "--test-samples",
        type=int,
        default=1000,
        help="æµ‹è¯•é›†æ ·æœ¬æ•° (ä»… --full-dataset æ¨¡å¼ï¼Œé»˜è®¤: 1000)"
    )
    
    args = parser.parse_args()
    
    if args.full_dataset:
        generate_full_dataset(
            train_samples=args.train_samples,
            val_samples=args.val_samples,
            test_samples=args.test_samples,
            output_dir=args.output if args.output != "data" else "data/ppo_dataset",
            seed=args.seed,
        )
    else:
        generate_training_data(
            n_samples=args.samples,
            scenario=args.scenario,
            output_dir=args.output,
            seed=args.seed,
        )


if __name__ == "__main__":
    main()
