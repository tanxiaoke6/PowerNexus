#!/usr/bin/env python3
"""
ç‹¬ç«‹æµ‹è¯•è„šæœ¬ï¼šéªŒè¯ Qwen2.5-VL æ¨¡å‹åŠ è½½
"""
import torch
from transformers import AutoProcessor

# å°è¯•å¯¼å…¥ Qwen2.5-VL æ¨¡å‹ç±»
try:
    from transformers import Qwen2_5_VLForConditionalGeneration
    print("âœ… Qwen2_5_VLForConditionalGeneration å¯¼å…¥æˆåŠŸ")
except ImportError:
    print("âŒ Qwen2_5_VLForConditionalGeneration å¯¼å…¥å¤±è´¥")
    Qwen2_5_VLForConditionalGeneration = None

# é…ç½®
MODEL_PATH = "/home/tanxk/xiaoke/Qwen2.5-VL-7B-Instruct"
DEVICE = "cuda:6"

print(f"\nğŸ“ æ¨¡å‹è·¯å¾„: {MODEL_PATH}")
print(f"ğŸ¯ ç›®æ ‡è®¾å¤‡: {DEVICE}")
print(f"ğŸ”§ PyTorch ç‰ˆæœ¬: {torch.__version__}")
print(f"ğŸ–¥ï¸  CUDA å¯ç”¨: {torch.cuda.is_available()}")

if torch.cuda.is_available():
    print(f"ğŸ“Š GPU æ•°é‡: {torch.cuda.device_count()}")
    for i in range(torch.cuda.device_count()):
        print(f"   GPU {i}: {torch.cuda.get_device_name(i)}")

print("\n" + "="*50)
print("å¼€å§‹åŠ è½½æ¨¡å‹...")
print("="*50)

# åŠ è½½ Processor
print("\n1. åŠ è½½ Processor...")
processor = AutoProcessor.from_pretrained(
    MODEL_PATH,
    trust_remote_code=True,
)
print("âœ… Processor åŠ è½½æˆåŠŸ")

# åŠ è½½æ¨¡å‹ - ç›´æ¥åˆ° GPU
print(f"\n2. åŠ è½½æ¨¡å‹ (ç›´æ¥åˆ° {DEVICE})...")
model_kwargs = {
    "trust_remote_code": True,
    "torch_dtype": torch.float16,
    "device_map": DEVICE,
}

try:
    if Qwen2_5_VLForConditionalGeneration is not None:
        model = Qwen2_5_VLForConditionalGeneration.from_pretrained(
            MODEL_PATH,
            **model_kwargs,
        )
        print("âœ… Qwen2_5_VLForConditionalGeneration åŠ è½½æˆåŠŸ!")
    else:
        print("âš ï¸ Qwen2_5_VLForConditionalGeneration ä¸å¯ç”¨ï¼Œå°è¯• AutoModel")
        from transformers import AutoModel
        model = AutoModel.from_pretrained(
            MODEL_PATH,
            **model_kwargs,
        )
        print("âœ… AutoModel åŠ è½½æˆåŠŸ!")
    
    # éªŒè¯æ¨¡å‹
    print(f"\n3. æ¨¡å‹éªŒè¯:")
    print(f"   - ç±»å‹: {type(model).__name__}")
    print(f"   - è®¾å¤‡: {next(model.parameters()).device}")
    print(f"   - å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()) / 1e9:.2f}B")
    
    # æ£€æŸ¥ generate æ–¹æ³•
    if hasattr(model, 'generate'):
        print("   - generate æ–¹æ³•: âœ… å¯ç”¨")
    else:
        print("   - generate æ–¹æ³•: âŒ ä¸å¯ç”¨")
    
    print("\n" + "="*50)
    print("ğŸ‰ VL æ¨¡å‹åŠ è½½æµ‹è¯•æˆåŠŸ!")
    print("="*50)
    
except Exception as e:
    print(f"\nâŒ åŠ è½½å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()
