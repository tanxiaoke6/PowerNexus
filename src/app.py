# -*- coding: utf-8 -*-
"""
PowerNexus - Streamlit ä»ªè¡¨æ¿

åŸºäº Qwen2.5 æ¨¡å‹çš„ç”µç½‘å·¡æ£€æ™ºèƒ½å†³ç­–ç³»ç»Ÿã€‚

åŠŸèƒ½:
- Qwen-VL è§†è§‰åˆ†æ
- RAG çŸ¥è¯†æ£€ç´¢
- RL ä¼˜åŒ–å†³ç­–
- ç³»ç»ŸçŠ¶æ€ç›‘æ§

è¿è¡Œæ–¹å¼:
    streamlit run src/app.py

ä½œè€…: PowerNexus Team
æ—¥æœŸ: 2025-12-18
"""

import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

import streamlit as st
import json
from datetime import datetime
import logging

try:
    from config.settings import config as global_config
except ImportError:
    global_config = None

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# ============================================================================
# è‡ªåŠ¨æ–‡æ¡£æ‘„å…¥
# ============================================================================

@st.cache_resource(show_spinner="æ­£åœ¨æ£€æŸ¥å¹¶æ‘„å…¥çŸ¥è¯†åº“æ–‡æ¡£...")
def auto_ingest_documents(manuals_dir: str = "data/manuals", use_mock: bool = True):
    """
    è‡ªåŠ¨æ‘„å…¥ data/manuals ç›®å½•ä¸‹çš„æ–‡æ¡£åˆ°çŸ¥è¯†åº“
    
    ä½¿ç”¨ Streamlit cache_resource ç¡®ä¿åªåœ¨å¯åŠ¨æ—¶æ‰§è¡Œä¸€æ¬¡
    
    Args:
        manuals_dir: æ–‡æ¡£ç›®å½•è·¯å¾„
        use_mock: æ˜¯å¦ä½¿ç”¨ Mock åµŒå…¥æ¨¡å‹
        
    Returns:
        dict: æ‘„å…¥ç»Ÿè®¡ä¿¡æ¯
    """
    manuals_path = PROJECT_ROOT / manuals_dir
    
    if not manuals_path.exists():
        return {"status": "skip", "message": f"ç›®å½•ä¸å­˜åœ¨: {manuals_dir}"}
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡æ¡£éœ€è¦æ‘„å…¥
    supported_extensions = {'.txt', '.md', '.markdown', '.pdf'}
    files = [f for f in manuals_path.rglob('*') 
             if f.is_file() and f.suffix.lower() in supported_extensions]
    
    if not files:
        return {"status": "skip", "message": "ç›®å½•ä¸ºç©ºï¼Œæ— éœ€æ‘„å…¥"}
    
    try:
        from src.rag.ingest import DocumentIngestor, IngestConfig
        
        # åˆ›å»ºæ‘„å…¥å™¨
        config = IngestConfig()
        ingestor = DocumentIngestor(config=config, use_mock=use_mock)
        
        # è·å–å½“å‰çŸ¥è¯†åº“æ–‡æ¡£æ•°
        initial_count = ingestor.get_stats().get('total_documents', 0)
        
        # å¦‚æœçŸ¥è¯†åº“å·²æœ‰æ–‡æ¡£ï¼Œè·³è¿‡æ‘„å…¥
        if initial_count > len(files):
            return {
                "status": "exists", 
                "message": f"çŸ¥è¯†åº“å·²æœ‰ {initial_count} ä¸ªæ–‡æ¡£å—",
                "count": initial_count
            }
        
        # æ‘„å…¥ç›®å½•
        total_chunks = ingestor.ingest_directory(str(manuals_path))
        
        return {
            "status": "success",
            "message": f"æˆåŠŸæ‘„å…¥ {len(files)} ä¸ªæ–‡ä»¶ï¼Œå…± {total_chunks} ä¸ªå—",
            "files": len(files),
            "chunks": total_chunks
        }
        
    except Exception as e:
        return {"status": "error", "message": f"æ‘„å…¥å¤±è´¥: {str(e)}"}


# æ‰§è¡Œè‡ªåŠ¨æ‘„å…¥ (ä»…åœ¨ RAG æ¨¡å—å¯ç”¨æ—¶)
def init_knowledge_base():
    """åˆå§‹åŒ–çŸ¥è¯†åº“å¹¶è‡ªåŠ¨æ‘„å…¥æ–‡æ¡£"""
    try:
        # è·å– Mock æ¨¡å¼è®¾ç½®
        use_mock = st.session_state.get('use_mock', True)
        result = auto_ingest_documents(use_mock=use_mock)
        return result
    except Exception as e:
        return {"status": "error", "message": str(e)}

# ============================================================================
# ç³»ç»Ÿæ£€æµ‹
# ============================================================================

# æ£€æµ‹ CUDA
CUDA_AVAILABLE = False
try:
    import torch
    CUDA_AVAILABLE = torch.cuda.is_available()
    TORCH_VERSION = torch.__version__
except ImportError:
    TORCH_VERSION = "æœªå®‰è£…"

# æ£€æµ‹å„æ¨¡å—
PERCEPTION_AVAILABLE = False
RAG_AVAILABLE = False
RL_AVAILABLE = False
LLM_AVAILABLE = False

try:
    from src.perception import DefectDetector, create_detector
    PERCEPTION_AVAILABLE = True
except ImportError as e:
    st.warning(f"æ„ŸçŸ¥æ¨¡å—åŠ è½½å¤±è´¥: {e}")

try:
    from src.rag import KnowledgeBase, init_knowledge_base_with_samples
    RAG_AVAILABLE = True
except ImportError as e:
    st.warning(f"RAG æ¨¡å—åŠ è½½å¤±è´¥: {e}")

try:
    from src.rl_engine import PPO_Agent, create_ppo_agent
    RL_AVAILABLE = True
except ImportError as e:
    st.warning(f"RL æ¨¡å—åŠ è½½å¤±è´¥: {e}")

try:
    from src.utils.llm_engine import LLMEngine, create_llm_engine
    LLM_AVAILABLE = True
except ImportError as e:
    pass

try:
    from PIL import Image
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False


# ============================================================================
# é¡µé¢é…ç½®
# ============================================================================

st.set_page_config(
    page_title="PowerNexus - ç”µç½‘æ™ºèƒ½å·¡æ£€ç³»ç»Ÿ",
    page_icon="âš¡",
    layout="wide",
    initial_sidebar_state="expanded",
)

# è‡ªå®šä¹‰ CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        background: linear-gradient(90deg, #1E88E5 0%, #00ACC1 50%, #00897B 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        text-align: center;
        padding: 1rem 0;
    }
    .sub-header {
        text-align: center;
        color: #666;
        margin-bottom: 2rem;
    }
    .status-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        text-align: center;
    }
    .metric-card {
        background: #f8f9fa;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #1E88E5;
    }
    .warning-box {
        background: #fff3cd;
        border: 1px solid #ffc107;
        border-radius: 8px;
        padding: 1rem;
        margin: 1rem 0;
    }
    .success-box {
        background: #d4edda;
        border: 1px solid #28a745;
        border-radius: 8px;
        padding: 1rem;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)


# ============================================================================
# ä¾§è¾¹æ 
# ============================================================================

with st.sidebar:
    st.image("https://via.placeholder.com/200x60?text=PowerNexus", width=200)
    st.markdown("---")
    
    st.header("âš™ï¸ æ¨¡å‹è®¾ç½®")
    
    # ä¼˜å…ˆä½¿ç”¨é…ç½®ä¸­çš„ Mock è®¾ç½®
    default_mock = True
    if global_config:
        default_mock = global_config.app.use_mock

    use_mock = st.checkbox(
        "Mock æ¨¡å¼ (æµ‹è¯•)",
        value=default_mock,
        help="ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å‹è¿›è¡Œæµ‹è¯•ï¼Œæ— éœ€åŠ è½½å®é™…æ¨¡å‹"
    )
    
    # ä¼˜å…ˆä½¿ç”¨é…ç½®ä¸­çš„æ–‡å­—å›ç­”è®¾ç½®
    default_use_llm = True
    if global_config:
        default_use_llm = getattr(global_config.qwen_llm, 'use_for_text', True)

    use_llm_for_text = st.checkbox(
        "æ–‡å­—å›ç­”ä½¿ç”¨ LLM",
        value=default_use_llm,
        help="å¦‚æœå…³é—­ï¼Œæ–‡å­—å›ç­”ä¹Ÿå°†ä½¿ç”¨ Qwen-VL æ¨¡å‹"
    )
    
    # æ˜¾ç¤ºå½“å‰ä½¿ç”¨çš„æ¨¡å‹
    st.markdown("---")
    st.markdown("**ğŸ¤– æ¨¡å‹ä¿¡æ¯:**")
    if global_config:
        st.caption(f"VL: {global_config.qwen_vl.model_name}")
        st.caption(f"LLM: {global_config.qwen_llm.model_name}")
        st.caption(f"Embedding: {global_config.rag.embedding_model}")
    else:
        st.caption("é…ç½®åŠ è½½å¤±è´¥")
    
    st.markdown("---")
    
    st.header("ğŸ“Š ç³»ç»ŸçŠ¶æ€")
    
    # ç³»ç»ŸçŠ¶æ€æ˜¾ç¤º
    col1, col2 = st.columns(2)
    with col1:
        if CUDA_AVAILABLE:
            st.success("GPU âœ“")
        else:
            st.warning("CPU")
    with col2:
        st.info(f"PyTorch {TORCH_VERSION[:5] if len(TORCH_VERSION) > 5 else TORCH_VERSION}")
    
    # æ¨¡å—çŠ¶æ€
    st.markdown("**æ¨¡å—çŠ¶æ€:**")
    modules = [
        ("æ„ŸçŸ¥", PERCEPTION_AVAILABLE),
        ("RAG", RAG_AVAILABLE),
        ("RL", RL_AVAILABLE),
        ("LLM", LLM_AVAILABLE),
    ]
    
    for name, available in modules:
        if available:
            st.markdown(f"- âœ… {name}")
        else:
            st.markdown(f"- âŒ {name}")
    
    # çŸ¥è¯†åº“è‡ªåŠ¨æ‘„å…¥çŠ¶æ€
    st.markdown("---")
    st.markdown("**ğŸ“š çŸ¥è¯†åº“:**")
    
    if RAG_AVAILABLE:
        # æ‰§è¡Œè‡ªåŠ¨æ‘„å…¥
        ingest_result = auto_ingest_documents(use_mock=use_mock)
        
        if ingest_result["status"] == "success":
            st.success(f"âœ… {ingest_result.get('chunks', 0)} å—")
        elif ingest_result["status"] == "exists":
            st.info(f"ğŸ“„ {ingest_result.get('count', 0)} å—")
        elif ingest_result["status"] == "skip":
            st.caption(ingest_result["message"])
        else:
            st.warning(f"âš ï¸ {ingest_result['message'][:30]}...")
        
        # æ‰‹åŠ¨åˆ·æ–°æŒ‰é’®
        if st.button("ğŸ”„ é‡æ–°æ‘„å…¥", help="æ¸…é™¤ç¼“å­˜å¹¶é‡æ–°æ‘„å…¥æ–‡æ¡£"):
            st.cache_resource.clear()
            st.rerun()
    else:
        st.caption("RAG æ¨¡å—æœªåŠ è½½")
    
    st.markdown("---")
    st.markdown("**âœï¸ ä½œè€…:** TanXiaoke")
    st.caption(f"â° {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")


# ============================================================================
# ä¸»é¡µé¢
# ============================================================================

# æ ‡é¢˜
st.markdown('<h1 class="main-header">âš¡ PowerNexus</h1>', unsafe_allow_html=True)
st.markdown('<p class="sub-header">Powered by Qwen2.5 | ç”µç½‘æ™ºèƒ½å·¡æ£€ä¸å†³ç­–ç³»ç»Ÿ</p>', unsafe_allow_html=True)

# CUDA è­¦å‘Š
if not CUDA_AVAILABLE:
    st.warning("âš ï¸ **GPU ä¸å¯ç”¨** - ç³»ç»Ÿè¿è¡Œåœ¨ CPU æ¨¡å¼ï¼Œæ¨ç†é€Ÿåº¦å¯èƒ½è¾ƒæ…¢ã€‚å»ºè®®å®‰è£… CUDA ç‰ˆæœ¬çš„ PyTorch ä»¥è·å¾—æ›´å¥½æ€§èƒ½ã€‚")

# ä¸»è¦åŠŸèƒ½åŒº
tab1, tab2, tab3, tab4 = st.tabs(["ğŸ” è§†è§‰æ£€æµ‹", "ğŸ“š çŸ¥è¯†æ£€ç´¢", "ğŸ¤– RL ä¼˜åŒ–", "ğŸ“Š ç³»ç»Ÿä¿¡æ¯"])


# ============================================================================
# Tab 1: è§†è§‰æ£€æµ‹
# ============================================================================

with tab1:
    st.header("ğŸ” Qwen-VL è§†è§‰åˆ†æ")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("ä¸Šä¼ å›¾åƒ")
        
        # å›¾åƒä¸Šä¼ 
        uploaded_file = st.file_uploader(
            "é€‰æ‹©ç”µåŠ›è®¾å¤‡å›¾åƒ",
            type=["jpg", "jpeg", "png"],
            help="æ”¯æŒ JPGã€PNG æ ¼å¼å›¾åƒ"
        )
        
        # ç¤ºä¾‹å›¾åƒ
        st.markdown("**æˆ–ä½¿ç”¨ç¤ºä¾‹å›¾åƒ:**")
        example_images = {
            "ç»ç¼˜å­è£‚çº¹": "data/images/insulator_defect.jpg",
            "æ­£å¸¸è®¾å¤‡": "data/images/insulator_normal.jpg",
            "é‡‘å…·é”ˆèš€": "data/images/metal_rust.jpg",
        }
        
        selected_example = st.selectbox("é€‰æ‹©ç¤ºä¾‹", list(example_images.keys()))
        
        if st.button("ä½¿ç”¨ç¤ºä¾‹å›¾åƒ"):
            st.session_state['selected_image_path'] = example_images[selected_example]
            st.session_state['image_source'] = 'example'
        
        # ç¡®å®šè¦åˆ†æçš„å›¾åƒ
        image_to_analyze = None
        image_path = None
        
        if uploaded_file is not None:
            image_to_analyze = Image.open(uploaded_file) if PIL_AVAILABLE else None
            # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
            temp_path = Path("data/images/temp_upload.jpg")
            temp_path.parent.mkdir(parents=True, exist_ok=True)
            if image_to_analyze:
                image_to_analyze.save(temp_path)
                image_path = str(temp_path)
                st.session_state['selected_image_path'] = image_path
                st.session_state['image_source'] = 'upload'
        elif 'selected_image_path' in st.session_state:
            image_path = st.session_state['selected_image_path']
            if Path(image_path).exists() and PIL_AVAILABLE:
                image_to_analyze = Image.open(image_path)
        
        if image_to_analyze:
            st.image(image_to_analyze, caption="å¾…åˆ†æå›¾åƒ", use_container_width=True)
        elif 'image_source' not in st.session_state:
            st.info("è¯·ä¸Šä¼ å›¾åƒæˆ–é€‰æ‹©ç¤ºä¾‹å›¾åƒ")
    
    with col2:
        st.subheader("åˆ†æç»“æœ")
        
        if st.button("ğŸ”¬ æ‰§è¡Œ Qwen-VL åˆ†æ", type="primary", use_container_width=True):
            if not PERCEPTION_AVAILABLE:
                st.error("æ„ŸçŸ¥æ¨¡å—æœªåŠ è½½")
            elif image_path is None:
                st.warning("è¯·å…ˆä¸Šä¼ æˆ–é€‰æ‹©å›¾åƒ")
            else:
                with st.spinner("Qwen-VL æ­£åœ¨åˆ†æå›¾åƒ..."):
                    try:
                        # åˆ›å»ºæ£€æµ‹å™¨
                        detector = create_detector(use_mock=use_mock)
                        
                        # æ˜¾ç¤ºå®é™…ä½¿ç”¨çš„æ¨¡å¼
                        if detector._use_mock:
                            st.caption("ğŸ”§ å½“å‰ä½¿ç”¨: Mock æ¨¡å‹")
                        else:
                            st.caption("ğŸš€ å½“å‰ä½¿ç”¨: Qwen2.5-VL çœŸå®æ¨¡å‹")
                        
                        # æ‰§è¡Œæ£€æµ‹
                        result = detector.detect(image_path)
                        
                        # æ˜¾ç¤ºç»“æœ
                        if result.defect_detected:
                            st.error("âš ï¸ æ£€æµ‹åˆ°ç¼ºé™·!")
                        else:
                            st.success("âœ… è®¾å¤‡çŠ¶æ€æ­£å¸¸")
                        
                        # è¯¦ç»†ä¿¡æ¯
                        col_a, col_b = st.columns(2)
                        with col_a:
                            st.metric("ç¼ºé™·ç±»å‹", result.defect_type)
                        with col_b:
                            st.metric("ä¸¥é‡ç¨‹åº¦", result.severity)
                        
                        st.metric("ç½®ä¿¡åº¦", f"{result.confidence:.1%}")
                        
                        st.markdown("**æè¿°:**")
                        st.info(result.description)
                        
                        # ğŸ› ï¸ RAG + LLM æŠ€æœ¯æ ‡å‡†æŒ‡å¯¼
                        if result.defect_detected and RAG_AVAILABLE:
                            st.markdown("---")
                            st.subheader("ğŸ› ï¸ æŠ€æœ¯æ ‡å‡†æŒ‡å¯¼ (RAG + LLM)")
                            
                            with st.spinner("æ­£åœ¨æ£€ç´¢æŠ€æœ¯æ ‡å‡†å¹¶ç”Ÿæˆå»ºè®®..."):
                                try:
                                    # å»¶è¿Ÿå¯¼å…¥ä»¥é¿å…å†²çª
                                    from src.rag.retriever import KnowledgeBase
                                    kb = KnowledgeBase(use_mock=use_mock)
                                    
                                    # ä½¿ç”¨ç¼ºé™·ç±»å‹å’Œæè¿°ä½œä¸ºæŸ¥è¯¢
                                    query_text = f"é’ˆå¯¹{result.defect_type}ï¼ˆ{result.description}ï¼‰ï¼Œç›¸å…³çš„ç”µåŠ›æŠ€æœ¯æ ‡å‡†å’Œå¤„ç†å»ºè®®æ˜¯ä»€ä¹ˆï¼Ÿ"
                                    
                                    rag_result = kb.query_and_synthesize(query_text, top_k=3)
                                    
                                    if rag_result.has_results:
                                        st.success("âœ… æŸ¥æ‰¾åˆ°ç›¸å…³æ ‡å‡†å»ºè®®ï¼š")
                                        st.markdown(rag_result.synthesized_answer)
                                        
                                        with st.expander("æŸ¥çœ‹å‚è€ƒæ ‡å‡†åŸæ–‡"):
                                            st.write(rag_result.formatted_context)
                                    else:
                                        st.warning("æœªåœ¨çŸ¥è¯†åº“ä¸­æ‰¾åˆ°ç›´æ¥åŒ¹é…çš„æ ‡å‡†ã€‚")
                                        
                                except Exception as rag_err:
                                    st.error(f"æ ‡å‡†æ£€ç´¢è¯†åˆ«å¤±è´¥: {rag_err}")
                        
                        # JSON è¾“å‡º
                        with st.expander("æŸ¥çœ‹ JSON è¾“å‡º"):
                            st.json(result.to_dict())
                        
                        detector.close()
                        
                    except Exception as e:
                        st.error(f"åˆ†æå¤±è´¥: {e}")
                        import traceback
                        with st.expander("é”™è¯¯è¯¦æƒ…"):
                            st.code(traceback.format_exc())


# ============================================================================
# Tab 2: çŸ¥è¯†æ£€ç´¢
# ============================================================================

with tab2:
    st.header("ğŸ“š RAG çŸ¥è¯†æ£€ç´¢")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("æŸ¥è¯¢é—®é¢˜")
        
        # çŸ¥è¯†åº“æ•°æ®é¢„è§ˆ
        if RAG_AVAILABLE:
            with st.expander("ğŸ“‹ æŸ¥çœ‹çŸ¥è¯†åº“æ•°æ®", expanded=False):
                try:
                    from src.rag.retriever import KnowledgeBase
                    kb_preview = KnowledgeBase(use_mock=use_mock)
                    kb_stats = kb_preview.get_stats()
                    doc_count = kb_stats.get('total_documents', 0)
                    
                    st.markdown(f"**æ–‡æ¡£å—æ•°é‡:** {doc_count}")
                    st.markdown(f"**é›†åˆåç§°:** {kb_stats.get('collection_name', 'N/A')}")
                    
                    # æ˜¾ç¤ºæ ·æœ¬æ•°æ®
                    if doc_count > 0 and hasattr(kb_preview, '_vector_store'):
                        try:
                            samples = kb_preview._vector_store._collection.peek(5)
                            if samples and 'documents' in samples:
                                st.markdown("**æ ·æœ¬æ–‡æœ¬å—:**")
                                for i, doc in enumerate(samples['documents'][:3]):
                                    preview = doc[:150] + "..." if len(doc) > 150 else doc
                                    st.text_area(f"å— {i+1}", preview, height=80, key=f"kb_sample_{i}")
                        except:
                            pass
                except Exception as e:
                    st.caption(f"æ— æ³•åŠ è½½çŸ¥è¯†åº“: {e}")
            
            st.markdown("---")
            
            # æ›´æ–°çŸ¥è¯†åº“åŠŸèƒ½
            if st.button("ğŸ”„ æ›´æ–°çŸ¥è¯†åº“", help="é‡æ–°æ‘„å…¥ /data/manuals ç›®å½•ä¸‹çš„æ–‡æ¡£", use_container_width=True):
                data_dir = os.path.join(global_config.project_root, "data", "manuals")
                if not os.path.exists(data_dir):
                    st.error(f"ç›®å½•ä¸å­˜åœ¨: {data_dir}")
                else:
                    with st.spinner("æ­£åœ¨æ›´æ–°çŸ¥è¯†åº“ï¼Œè¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´..."):
                        try:
                            # å»¶è¿Ÿå¯¼å…¥ä»¥é¿å…å¾ªç¯ä¾èµ–
                            from src.rag.ingest import DocumentIngestor
                            
                            ingestor = DocumentIngestor(use_mock=use_mock)
                            
                            # å…ˆæ¸…ç©ºå·²æœ‰çŸ¥è¯†åº“ä»¥è¿›è¡Œå…¨é¢æ›´æ–°
                            st.info("æ­£åœ¨æ¸…ç©ºæ—§æ•°æ®...")
                            ingestor.vector_store.clear()
                            
                            count = ingestor.ingest_directory(data_dir)
                            
                            if count > 0:
                                st.success(f"âœ… æ›´æ–°æˆåŠŸï¼å…±æ‘„å…¥ {count} ä¸ªæ–‡æ¡£å—ã€‚")
                                # å¼ºåˆ¶åˆ·æ–°é¡µé¢ä»¥æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                                st.rerun()
                            else:
                                st.warning("æœªæ‰¾åˆ°æ–°æ–‡æ¡£æˆ–æ‘„å…¥å¤±è´¥ã€‚")
                                
                        except Exception as e:
                            st.error(f"æ›´æ–°å¤±è´¥: {e}")
                            logger.error(f"çŸ¥è¯†åº“æ›´æ–°å¤±è´¥: {e}")
        
        st.markdown("---")
        
        # é¢„è®¾é—®é¢˜
        preset_questions = [
            "å˜å‹å™¨ç»ç¼˜ç”µé˜»æµ‹é‡çš„ç¯å¢ƒè¦æ±‚æ˜¯ä»€ä¹ˆï¼Ÿ",
            "ç»ç¼˜å­è£‚çº¹åº”è¯¥å¦‚ä½•å¤„ç†ï¼Ÿ",
            "é«˜æ¸©ç¯å¢ƒä¸‹è®¾å¤‡è¿è¡Œæœ‰ä»€ä¹ˆæ³¨æ„äº‹é¡¹ï¼Ÿ",
            "è´Ÿè·è½¬ç§»æ“ä½œçš„æµç¨‹æ˜¯ä»€ä¹ˆï¼Ÿ",
            "åœé€ç”µæ“ä½œé¡ºåºæ˜¯ä»€ä¹ˆï¼Ÿ",
        ]
        
        question_type = st.radio("é—®é¢˜æ¥æº", ["é¢„è®¾é—®é¢˜", "è‡ªå®šä¹‰é—®é¢˜"])
        
        if question_type == "é¢„è®¾é—®é¢˜":
            question = st.selectbox("é€‰æ‹©é—®é¢˜", preset_questions)
        else:
            question = st.text_area("è¾“å…¥é—®é¢˜", placeholder="è¯·è¾“å…¥æ‚¨çš„æŠ€æœ¯é—®é¢˜...")
        
        top_k = st.slider("æ£€ç´¢ç»“æœæ•°é‡", 1, 10, 3)
    
    with col2:
        st.subheader("æ£€ç´¢ç»“æœ")
        
        if st.button("ğŸ” æ‰§è¡Œ RAG æ£€ç´¢", type="primary", use_container_width=True):
            if not RAG_AVAILABLE:
                st.error("RAG æ¨¡å—æœªåŠ è½½")
            elif not question:
                st.warning("è¯·è¾“å…¥é—®é¢˜")
            else:
                with st.spinner("æ­£åœ¨æ£€ç´¢çŸ¥è¯†åº“..."):
                    try:
                        # ä½¿ç”¨æ‘„å…¥äº†çœŸå®æ•°æ®çš„çŸ¥è¯†åº“
                        from src.rag.retriever import KnowledgeBase
                        kb = KnowledgeBase(use_mock=use_mock)
                        
                        # æ˜¾ç¤ºçŸ¥è¯†åº“çŠ¶æ€
                        kb_stats = kb.get_stats()
                        doc_count = kb_stats.get('total_documents', 0)
                        if kb._use_mock:
                            st.caption(f"ğŸ”§ Mock æ¨¡å¼ | æ–‡æ¡£: {doc_count} å—")
                        else:
                            st.caption(f"ğŸš€ çœŸå®åµŒå…¥æ¨¡å‹ | æ–‡æ¡£: {doc_count} å—")
                        
                        # æ£€ç´¢
                        result = kb.query(question, top_k=top_k)
                        
                        st.success(f"âœ… æ‰¾åˆ° {result.num_results} æ¡ç›¸å…³ç»“æœ")
                        
                        # æ˜¾ç¤ºä¸Šä¸‹æ–‡
                        st.markdown("**æ£€ç´¢åˆ°çš„å‚è€ƒèµ„æ–™:**")
                        st.text_area("ä¸Šä¸‹æ–‡", result.formatted_context, height=200)
                        
                        # Qwen åˆæˆç­”æ¡ˆ
                        if hasattr(kb, 'query_and_synthesize') and LLM_AVAILABLE:
                            st.markdown("**Qwen LLM ç”Ÿæˆçš„ç­”æ¡ˆ:**")
                            synth_result = kb.query_and_synthesize(question, top_k=top_k)
                            st.info(synth_result.synthesized_answer)
                        
                        # å®Œæ•´æç¤º
                        with st.expander("æŸ¥çœ‹å®Œæ•´ LLM æç¤º"):
                            st.code(result.prompt, language="markdown")
                        
                    except Exception as e:
                        st.error(f"æ£€ç´¢å¤±è´¥: {e}")
                        import traceback
                        with st.expander("é”™è¯¯è¯¦æƒ…"):
                            st.code(traceback.format_exc())


# ============================================================================
# Tab 3: RL ä¼˜åŒ–
# ============================================================================

with tab3:
    st.header("ğŸ¤– RL ä¼˜åŒ–å†³ç­–")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("ç”µç½‘çŠ¶æ€è¾“å…¥")
        
        # æ•°æ®æºé€‰æ‹©
        data_source = st.radio(
            "æ•°æ®æ¥æº",
            ["ä»æ–‡ä»¶åŠ è½½ (grid_states.npz)", "æ‰‹åŠ¨è®¾ç½®è´Ÿè·æ°´å¹³"],
            horizontal=True
        )
        
        import numpy as np
        
        # åˆå§‹åŒ–å˜é‡
        line_loads = None
        max_load = 0.5
        current_state_index = 0
        
        if data_source == "ä»æ–‡ä»¶åŠ è½½ (grid_states.npz)":
            # æ˜¾ç¤º IEEE ç³»ç»Ÿä¿¡æ¯
            st.markdown("**ğŸ“Š IEEE 14-Bus ç³»ç»Ÿ**")
            st.caption("5 å‘ç”µæœº | 11 è´Ÿè· | 20 çº¿è·¯ | 57 æ‹“æ‰‘å…ƒç´ ")
            
            # ä» grid_states.npz åŠ è½½æ•°æ®
            data_path = "data/grid_states.npz"
            
            try:
                if Path(data_path).exists():
                    data = np.load(data_path, allow_pickle=True)
                    n_samples = int(data['n_samples'])
                    
                    st.success(f"âœ… å·²åŠ è½½ {n_samples} ä¸ªç”µç½‘çŠ¶æ€")
                    
                    # é€‰æ‹©çŠ¶æ€ç´¢å¼•
                    current_state_index = st.slider(
                        "é€‰æ‹©çŠ¶æ€å¿«ç…§",
                        0, n_samples - 1, 0,
                        help="ä»é¢„ç”Ÿæˆçš„ç”µç½‘çŠ¶æ€ä¸­é€‰æ‹©ä¸€ä¸ª"
                    )
                    
                    # è¯»å–å½“å‰çŠ¶æ€çš„æ•°æ®
                    line_loads = data['rho'][current_state_index]
                    gen_p = data['gen_p'][current_state_index]
                    gen_v = data['gen_v'][current_state_index]
                    load_p = data['load_p'][current_state_index]
                    load_q = data['load_q'][current_state_index]
                    topo_vect = data['topo_vect'][current_state_index]
                    scenario = str(data['scenarios'][current_state_index])
                    
                    max_load = float(line_loads.max())
                    
                    # æ˜¾ç¤ºåœºæ™¯ä¿¡æ¯
                    st.info(f"ğŸ“Š åœºæ™¯: **{scenario}** | çŠ¶æ€ç´¢å¼•: {current_state_index}")
                    
                else:
                    st.warning(f"âš ï¸ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
                    st.markdown("è¯·å…ˆè¿è¡Œä»¥ä¸‹å‘½ä»¤ç”Ÿæˆæ•°æ®:")
                    st.code("python tools/simulate_grid_state.py -n 100 -s mixed -o data/grid_states.npz")
                    line_loads = None
                    
            except Exception as e:
                st.error(f"åŠ è½½æ•°æ®å¤±è´¥: {e}")
                line_loads = None
        
        else:
            # æ‰‹åŠ¨è®¾ç½®æ¯æ¡çº¿è·¯è´Ÿè½½ç‡
            st.markdown("**ğŸ“Š IEEE 14-Bus ç³»ç»Ÿ**")
            st.caption("5 å‘ç”µæœº | 11 è´Ÿè· | 20 çº¿è·¯ | 57 æ‹“æ‰‘å…ƒç´ ")
            
            st.markdown("---")
            st.markdown("**çº¿è·¯è´Ÿè½½ç‡æ‰‹åŠ¨è®¾ç½®:**")
            
            # é¢„è®¾æ¨¡å¼é€‰æ‹©
            preset_mode = st.selectbox(
                "é¢„è®¾è´Ÿè·æ¨¡å¼",
                ["è‡ªå®šä¹‰", "æ­£å¸¸è¿è¡Œ", "é«˜å³°è´Ÿè·", "å±€éƒ¨è¿‡è½½", "ç´§æ€¥çŠ¶æ€"]
            )
            
            # æ ¹æ®é¢„è®¾åˆå§‹åŒ–
            if preset_mode == "æ­£å¸¸è¿è¡Œ":
                default_loads = [0.4 + i * 0.02 for i in range(20)]
            elif preset_mode == "é«˜å³°è´Ÿè·":
                default_loads = [0.7 + (i % 5) * 0.05 for i in range(20)]
            elif preset_mode == "å±€éƒ¨è¿‡è½½":
                default_loads = [0.5] * 15 + [0.95, 0.98, 1.02, 0.88, 0.92]
            elif preset_mode == "ç´§æ€¥çŠ¶æ€":
                default_loads = [0.8 + (i % 4) * 0.1 for i in range(20)]
            else:
                # è‡ªå®šä¹‰æ¨¡å¼ï¼Œä½¿ç”¨ session_state å­˜å‚¨çš„å€¼æˆ–é»˜è®¤å€¼
                if 'manual_line_loads' not in st.session_state:
                    st.session_state['manual_line_loads'] = [0.5] * 20
                default_loads = st.session_state['manual_line_loads']
            
            # åˆ›å»ºçº¿è·¯è´Ÿè½½ç‡æ»‘å—
            line_loads = []
            
            # åˆ†ä¸¤åˆ—æ˜¾ç¤º 10 æ¡çº¿è·¯
            col_l1, col_l2 = st.columns(2)
            
            with col_l1:
                st.markdown("**L1-L10:**")
                for i in range(10):
                    val = st.slider(
                        f"L{i+1}", 0.0, 1.2, 
                        float(default_loads[i]) if i < len(default_loads) else 0.5,
                        0.05,
                        key=f"line_{i}",
                        help=f"çº¿è·¯ {i+1} è´Ÿè½½ç‡"
                    )
                    line_loads.append(val)
            
            with col_l2:
                st.markdown("**L11-L20:**")
                for i in range(10, 20):
                    val = st.slider(
                        f"L{i+1}", 0.0, 1.2,
                        float(default_loads[i]) if i < len(default_loads) else 0.5,
                        0.05,
                        key=f"line_{i}",
                        help=f"çº¿è·¯ {i+1} è´Ÿè½½ç‡"
                    )
                    line_loads.append(val)
            
            line_loads = np.array(line_loads)
            st.session_state['manual_line_loads'] = line_loads.tolist()
            max_load = float(line_loads.max())
        
        # æ˜¾ç¤ºçº¿è·¯è´Ÿè½½ç‡
        if line_loads is not None:
            st.markdown("---")
            st.markdown(f"**ğŸ“ˆ çº¿è·¯è´Ÿè½½ç‡ ({len(line_loads)} æ¡çº¿è·¯):**")
            
            # ç»Ÿè®¡ä¿¡æ¯
            col_stat1, col_stat2, col_stat3 = st.columns(3)
            with col_stat1:
                st.metric("æœ€å¤§è´Ÿè½½ç‡", f"{line_loads.max():.1%}")
            with col_stat2:
                st.metric("å¹³å‡è´Ÿè½½ç‡", f"{line_loads.mean():.1%}")
            with col_stat3:
                overload_count = int((line_loads > 0.95).sum())
                st.metric("è¿‡è½½çº¿è·¯", f"{overload_count} æ¡", 
                         delta=f"{overload_count}" if overload_count > 0 else None,
                         delta_color="inverse")
            
            # æ˜¾ç¤ºå‰ 10 æ¡çº¿è·¯çš„è¿›åº¦æ¡
            st.markdown("**çº¿è·¯çŠ¶æ€ (å‰10æ¡):**")
            for i, load in enumerate(line_loads[:10]):
                # æ ¹æ®è´Ÿè½½ç‡é€‰æ‹©é¢œè‰²æç¤º
                if load > 0.95:
                    status = "ğŸ”´"
                elif load > 0.8:
                    status = "ğŸŸ "
                elif load > 0.6:
                    status = "ğŸŸ¡"
                else:
                    status = "ğŸŸ¢"
                
                # ç¡®ä¿ progress å€¼åœ¨ 0-1 ä¹‹é—´
                progress_val = min(1.0, max(0.0, float(load)))
                st.progress(progress_val, text=f"{status} L{i+1}: {load:.1%}")
            
            # å¦‚æœæœ‰æ›´å¤šçº¿è·¯ï¼Œæ˜¾ç¤ºå¯å±•å¼€åŒºåŸŸ
            if len(line_loads) > 10:
                with st.expander(f"æŸ¥çœ‹æ›´å¤šçº¿è·¯ (L11 - L{len(line_loads)})"):
                    for i, load in enumerate(line_loads[10:], start=10):
                        if load > 0.95:
                            status = "ğŸ”´"
                        elif load > 0.8:
                            status = "ğŸŸ "
                        elif load > 0.6:
                            status = "ğŸŸ¡"
                        else:
                            status = "ğŸŸ¢"
                        progress_val = min(1.0, max(0.0, float(load)))
                        st.progress(progress_val, text=f"{status} L{i+1}: {load:.1%}")
        
        # çŠ¶æ€æè¿°
        if line_loads is not None:
            overload_lines = [i+1 for i, l in enumerate(line_loads) if l > 0.95]
            if overload_lines:
                grid_state = f"æœ€å¤§è´Ÿè½½ç‡ {max_load:.0%}ï¼Œè¿‡è½½çº¿è·¯: {overload_lines}"
            else:
                grid_state = f"æœ€å¤§è´Ÿè½½ç‡ {max_load:.0%}ï¼Œæ‰€æœ‰çº¿è·¯è¿è¡Œæ­£å¸¸"
        else:
            grid_state = "æ— æ•°æ®"
        st.text_area("ç”µç½‘çŠ¶æ€æè¿°", grid_state, height=80)
    
    with col2:
        st.subheader("RL å†³ç­–ç»“æœ")
        
        if st.button("ğŸ¯ æ‰§è¡Œ RL ä¼˜åŒ–", type="primary", use_container_width=True):
            if not RL_AVAILABLE:
                st.error("RL æ¨¡å—æœªåŠ è½½")
            elif line_loads is None:
                st.warning("è¯·å…ˆåŠ è½½ç”µç½‘çŠ¶æ€æ•°æ®")
            else:
                with st.spinner("PPO æ™ºèƒ½ä½“æ­£åœ¨åˆ†æ..."):
                    try:
                        # åˆ›å»ºæ™ºèƒ½ä½“
                        agent = create_ppo_agent(use_mock=use_mock)
                        
                        # æ„é€ å®Œæ•´è§‚æµ‹å‘é‡
                        if data_source == "ä»æ–‡ä»¶åŠ è½½ (grid_states.npz)" and 'gen_p' in dir():
                            # ä½¿ç”¨ä»æ–‡ä»¶åŠ è½½çš„å®Œæ•´æ•°æ®
                            obs = np.concatenate([
                                line_loads.astype(np.float32),      # rho (20)
                                gen_p.astype(np.float32),           # gen_p (5)
                                gen_v.astype(np.float32),           # gen_v (5)
                                load_p.astype(np.float32),          # load_p (11)
                                load_q.astype(np.float32),          # load_q (11)
                                topo_vect.astype(np.float32),       # topo_vect (57)
                            ])
                            st.caption(f"ğŸ“ è§‚æµ‹å‘é‡ç»´åº¦: {obs.shape[0]}")
                        else:
                            # æ‰‹åŠ¨æ¨¡å¼: æ„é€ æ¨¡æ‹Ÿè§‚æµ‹
                            obs = np.concatenate([
                                line_loads.astype(np.float32),
                                np.array([50.0, 30.0, 20.0, 25.0, 15.0], dtype=np.float32),  # gen_p
                                np.ones(5, dtype=np.float32),                                 # gen_v
                                np.random.uniform(10, 40, 11).astype(np.float32),            # load_p
                                np.random.uniform(3, 15, 11).astype(np.float32),             # load_q
                                np.ones(57, dtype=np.float32),                                # topo_vect
                            ])
                        
                        # é¢„æµ‹åŠ¨ä½œ
                        action = agent.predict_action(obs)
                        action_name = agent.get_action_name(action)
                        
                        # æ˜¾ç¤ºå†³ç­–
                        if action == 0:
                            st.success("âœ… RL å»ºè®®: ä¿æŒå½“å‰æ‹“æ‰‘")
                        else:
                            st.warning(f"âš ï¸ RL å»ºè®®: {action_name}")
                        
                        st.metric("æ¨èåŠ¨ä½œ", action_name)
                        st.metric("åŠ¨ä½œç¼–å·", action)
                        
                        # è§£é‡Š
                        if hasattr(agent, 'interpret_action'):
                            st.markdown("**Qwen LLM å†³ç­–è§£é‡Š:**")
                            explanation = agent.interpret_action(action, grid_state)
                            st.info(explanation)
                        
                        # å®‰å…¨è¯„ä¼°
                        safe_to_disconnect = max_load < 0.8
                        st.markdown("**ç»´æŠ¤å¯è¡Œæ€§è¯„ä¼°:**")
                        if safe_to_disconnect:
                            st.success("âœ… å½“å‰å¯å®‰å…¨è¿›è¡Œç»´æŠ¤æ“ä½œ")
                        else:
                            st.error("âŒ è´Ÿè·è¿‡é«˜ï¼Œå»ºè®®å…ˆè¿›è¡Œè´Ÿè·è½¬ç§»")
                        
                        # æ˜¾ç¤ºè¯¦ç»†è§‚æµ‹ä¿¡æ¯
                        with st.expander("æŸ¥çœ‹è¯¦ç»†è§‚æµ‹æ•°æ®"):
                            st.json({
                                "rho_max": float(line_loads.max()),
                                "rho_mean": float(line_loads.mean()),
                                "overload_lines": int((line_loads > 0.95).sum()),
                                "obs_dim": len(obs),
                            })
                        
                    except Exception as e:
                        st.error(f"RL å†³ç­–å¤±è´¥: {e}")
                        import traceback
                        with st.expander("æŸ¥çœ‹é”™è¯¯è¯¦æƒ…"):
                            st.code(traceback.format_exc())


# ============================================================================
# Tab 4: ç³»ç»Ÿä¿¡æ¯
# ============================================================================

with tab4:
    st.header("ğŸ“Š ç³»ç»Ÿä¿¡æ¯")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ç¯å¢ƒä¿¡æ¯")
        
        info_data = {
            "é¡¹ç›®": "PowerNexus",
            "ç‰ˆæœ¬": "1.0.0",
            "Python": sys.version.split()[0],
            "PyTorch": TORCH_VERSION,
            "CUDA": "å¯ç”¨" if CUDA_AVAILABLE else "ä¸å¯ç”¨",
            "æ¨¡å¼": "Mock" if use_mock else "ç”Ÿäº§",
        }
        
        for key, value in info_data.items():
            st.markdown(f"**{key}:** {value}")
        
        st.markdown("---")
        
        st.subheader("æ¨¡å‹é…ç½®")
        
        model_info = {
            "è§†è§‰æ¨¡å‹": "Qwen/Qwen2.5-VL-7B-Instruct",
            "æ–‡æœ¬æ¨¡å‹": "Qwen/Qwen2.5-7B-Instruct",
            "åµŒå…¥æ¨¡å‹": "sentence-transformers/all-MiniLM-L6-v2",
            "RL ç®—æ³•": "PPO (Stable-Baselines3)",
            "ç²¾åº¦": "FP16",
        }
        
        for key, value in model_info.items():
            st.markdown(f"**{key}:** `{value}`")
    
    with col2:
        st.subheader("ç³»ç»Ÿæ¶æ„")
        
        st.markdown("""
        ```
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚           PowerNexus æ¶æ„           â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚                                     â”‚
        â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
        â”‚   â”‚ Qwen-VL â”‚   â”‚  Qwen   â”‚        â”‚
        â”‚   â”‚  è§†è§‰   â”‚   â”‚  æ–‡æœ¬   â”‚        â”‚
        â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜        â”‚
        â”‚        â”‚             â”‚             â”‚
        â”‚   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”        â”‚
        â”‚   â”‚      LLM å¼•æ“         â”‚        â”‚
        â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
        â”‚               â”‚                    â”‚
        â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
        â”‚   â”‚      æ™ºèƒ½ä½“å·¥ä½œæµ      â”‚        â”‚
        â”‚   â”‚  Seeâ†’Thinkâ†’Decideâ†’Act â”‚        â”‚
        â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
        â”‚               â”‚                    â”‚
        â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
        â”‚ â”‚                           â”‚      â”‚
        â”‚ â”‚  â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”‚      â”‚
        â”‚ â”‚  â”‚æ„ŸçŸ¥ â”‚ â”‚ RAG â”‚ â”‚ RL  â”‚ â”‚      â”‚
        â”‚ â”‚  â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â”‚      â”‚
        â”‚ â”‚                           â”‚      â”‚
        â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
        â”‚                                     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        ```
        """)
        
        st.markdown("---")
        
        # å¿«é€Ÿæ“ä½œ
        st.subheader("å¿«é€Ÿæ“ä½œ")
        
        if st.button("ğŸ”„ åˆ·æ–°ç³»ç»ŸçŠ¶æ€"):
            st.rerun()
        
        if st.button("ğŸ—‘ï¸ æ¸…é™¤ç¼“å­˜"):
            st.cache_data.clear()
            st.success("ç¼“å­˜å·²æ¸…é™¤")


# ============================================================================
# é¡µè„š
# ============================================================================

st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #888; padding: 1rem;">
    <p>PowerNexus Â© 2025 | Powered by Qwen2.5 | 
    <a href="https://github.com/QwenLM/Qwen2.5" target="_blank">Qwen2.5</a></p>
</div>
""", unsafe_allow_html=True)
